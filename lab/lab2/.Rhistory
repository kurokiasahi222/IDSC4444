#Load the package arules in R
#install.packages("arules")
library(arules)
#We cannot load transaction data using the traditional read.csv
temp <- read.csv("coffeeshop.csv", header = FALSE)
#We cannot load transaction data using the traditional read.csv
temp <- read.csv("coffeeshop.csv", header = FALSE)
#We cannot load transaction data using the traditional read.csv
temp <- read.csv("coffeeshop.csv", header = FALSE)
#Load the package arules in R
#install.packages("arules")
library(arules)
#We cannot load transaction data using the traditional read.csv
temp <- read.csv("coffeeshop.csv", header = FALSE)
temp
#We need to use a different function
#Load the coffeshop transactions using read.transactions()
#we specify that the format of our data is "basket"
#sep ="," is used to specify how the data are saved in the csv file
#rm.duplicates will remove duplicate items in the same transaction
coffee_data = read.transactions("coffeeshop.csv", format = "basket",
sep = ",", rm.duplicates = TRUE)
View(coffee_data)
Summary(coffee_data)
Summary(coffee_data)
inspect(coffee_data)
#To learn the unique items existing in the dataset
itemInfo(coffee_data)
#To learn how many items in each transaction, we can use
size(coffee_data)
#To find the support percentage of each unique item (frequency)
itemFrequency(coffee_data)
#To find the support count, add the option type and set = absolute
itemFrequency(coffee_data, type = "absolute")
#To plot the support %
itemFrequencyPlot(coffee_data, ylim = c(0, 1), main =
"Support %", col = "steelblue3")
?itemFrequency
#we can have the items ordered based on support %
#(or differently, if you have a large dataset, you can ask to see only the
#top N items, where N is a number of your choice)
itemFrequencyPlot(coffee_data, ylim = c(0, 1), main =
"Support %", col = "steelblue3", topN = 3)
#To plot the support %
itemFrequencyPlot(coffee_data, ylim = c(0, 1), main =
"Support %", col = "steelblue3")
#You can change the graph to be horizontal
itemFrequencyPlot(coffee_data, main = "Support %", col =
"steelblue3", topN = 5, hor = TRUE, xlim = c(0,1))
#Visualize the entire dataset
#On the horizontal axis, you have individual items; each column tells us in which
#transaction the corresponding item appears; on the vertical axis, you have the transactions
#each row tells us which items are included in the corresponding transaction
#
itemLabels <- c("bagel", "chocolate", "coffee", "cookie", "tea")
image(coffee_data, xlab = itemLabels)
?image
coffee_data
colnames(coffee_data)
image(coffee_data, xlab = colnames(coffee_data))
subset(coffee_data, items %in% c("coffee"))
subset(coffee_data, items %in% c("cookie", "tea"))
subtemp <- subset(coffee_data, items %in% c("coffee"))
inspect(subtemp)
#If we want to know transactions that contain ALL the items specified,
#we need to use the operator %ain%, AND
subset(coffee_data, items %ain% c("cookie", "tea"))
#contingency table, use crosstable
#We can compute different measures for pairs of items
#use support for support percentage
crossTable(coffee_data, sort = TRUE, measure = "support")
#contingency table, use crosstable
#We can compute different measures for pairs of items
#use support for support percentage
?crossTable
#use count for support count
crossTable(coffee_data, sort = TRUE, measure = "count")
#use lift for the lift ratio
crossTable(coffee_data, sort = TRUE, measure = "lift")
crossTable(coffee_data, sort = TRUE, measure = "Confidence")
#contingency table, use crosstable
#We can compute different measures for pairs of items
#use support for support percentage
?crossTable
#Show all the itemsets above a certain support threshold
coffee_itm <- eclat(coffee_data, parameter = list(support = 0.5))
#Show all the itemsets above a certain support threshold
?eclat
coffee_itm <- eclat(coffee_data
, parameter = list(support = 0.5))
inspect(coffee_itm)
#mine frequent item-sets
#specify the parameters, such as minsupp and the target of your analysis
#"frequent" means we are interested in the frequent item-sets
?list
frequent <- apriori(coffee_data, parameter = list(supp = 0.5, target = "frequent"))
#we can get a summary of the frequent item-sets
summary(frequent)
coffee_data
inspect(coffee_data)
?apiori
?apriori
#we can get a summary of the frequent item-sets
summary(frequent)
#mine association rules
#specify minsupp and minconfidence
rules <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.7, target = "rules"))
inspect(rules)
inspect(rules2)
#we can also specify the min number of items that should be included in the
#association rule
rules2 <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.8, target = "rules", minlen = 3))
inspect(rules2)
#Combine inspect with sort
inspect(sort(rules, by = "support"))
#Combine inspect with subset
inspect(subset(rules, lhs %in% "tea"))
inspect(subset(rules, rhs %in% "tea"))
library(readr)
coffeeshop_binary <- read_csv("coffeeshop_binary.csv")
View(coffeeshop_binary)
#Binary Matrix Format
#Load the data using the read.csv()
coffee_binary = read.csv("coffeeshop_binary.csv")
#Then transform the data to matrix format
coffee_matrix = as.matrix(coffee_binary)
#Useful package for association rules reporting and visualization
#install.packages("arulesViz")
library(arulesViz)
#It shows an HTML interactive table
inspectDT(rules)
#We can plot the rules as a graph
plot(rules, method = "graph")
#mine association rules
#specify minsupp and minconfidence
rules <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.7, target = "rules"))
inspect(rules)
#We can plot the rules as a graph
set.seed(3)
plot(rules, method = "graph")
plot(rules, method = "graph")
#If you have a large dataset and a graph becomes infeasible
#we can plot a scatterplot of the rules, where the color changes based
#on a chosen measure
plot(rules, measure = c("support", "lift"), shading = "confidence")
#mine association rules
#specify minsupp and minconfidence
rules <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.8, target = "rules"))
inspect(rules)
#mine association rules
#specify minsupp and minconfidence
rules <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.5, target = "rules"))
inspect(rules)
#mine association rules
#specify minsupp and minconfidence
rules <- apriori(coffee_data, parameter = list(supp = 0.5, conf = 0.8, target = "rules"))
inspect(rules)
plot(rules, method = "graph")
# P1: Import this dataset as transaction data
# Think about parameters including format, sep, and rm.duplicates
# Write your code below:
supermarket <- read.transactions("supermarket.csv")
# P1: Import this dataset as transaction data
# Think about parameters including format, sep, and rm.duplicates
# Write your code below:
?read.transactions
inspect(supermarket)
supermarket <- read.transactions("supermarket.csv", format ="basket",
sep = ",", rm.duplicates = TRUE)
inspect(supermarket)
# P2: Understand the supermarket data
# Which unique items are there in all shopping baskets?
# Write your code below:
unique(supermarket)
# P2: Understand the supermarket data
# Which unique items are there in all shopping baskets?
# Write your code below:
summary(supermarket)
# P2: Understand the supermarket data
# Which unique items are there in all shopping baskets?
# Write your code below:
itemInfo(supermarket)
# P3: Understand the supermarket data
# How many transactions contain purchases of Butter?
# Write your code below:
size(supermarket)
itemFrequency(supermarket)
# P3: Understand the supermarket data
# How many transactions contain purchases of Butter?
# Write your code below:
subset(supermarket, items %in% c("Butter"))
# P3: Understand the supermarket data
# How many transactions contain purchases of Butter?
# Write your code below:
butter_data <- subset(supermarket, items %in% c("Butter"))
inspect(butter_data)
#How many transactions contain purchase of Butter and Cheese?
# Write your code below:
butter_cheeze <- ssubset(supermarket, items %ain% c("Butter", "Cheese"))
#How many transactions contain purchase of Butter and Cheese?
# Write your code below:
butter_cheeze <- subset(supermarket, items %ain% c("Butter", "Cheese"))
inspect(butter_cheeze)
# P4: Understand the supermarket data
# Plot the support percentage of each item, for the top 4 items
# Write your code below:
?itemFrequencyPlot
itemFrequencyPlot(supermarket, topN = 4)
itemFrequencyPlot(supermarket, main = "Support %",
topN = 4)
itemFrequencyPlot(coffee_data, ylim = c(0, 1), main =
"Support %", col = "steelblue3")
# P6: Mine association rules
# Find all association rules with minsupp = 0.375 and minconf = 0.65 and with a min number of items = 2
# Write your code below:
?apriorix
# P6: Mine association rules
# Find all association rules with minsupp = 0.375 and minconf = 0.65 and with a min number of items = 2
# Write your code below:
?apriori
rules <- apriori(supermarket, parameter = list(supp = 0.375, conf = 0.65, minlen = 2))
# P7: Mine association rules
# Inspect the found rules, in the order of decreasing lift ratio
# Write your code below:
inspect(rules)
inspect(sort(rules, by = "lift"))
itemFrequencyPlot(supermarket, ylim = c(0, 1), main =
"Support %", col = "red", topN = 4)
supermarket_rules <- apriori(supermarket,parameter = list(support=0.375,confidence=0.65, target = "rules", minlen = 2))
inspect(sort(supermarket_rules, by = "lift"))
inspect(sort(rules, by = "lift"))
# P1: Import this dataset as transaction data
# Think about the three steps of importing
# Write your code below:
?read.transactions
book_data_frame = read.csv("book.csv")
View(book_data_frame)
book_data <- as.matrix("book.csv")
View(book_data)
book_data <- as.matrixbook.csv)
book_data <- as.matrix(book.csv)
book_matrix <- as.matrix(book_data_frame)
View(book_matrix)
?as
book_transactions <- as(book_matrix, "transactions")
View(book_transactions)
inspect(book_transactions)
inspect(head(book_transactions))
summary(book_transactions)
?itemFrequencyPlot
itemFrequencyPlot(book_transactions, type = "absolute", topN = 100)
itemFrequencyPlot(book_transactions, type = "absolute", topN = 10)
itemFrequencyPlot(book_transactions, type = "absolute")
itemFrequencyPlot(book_transactions, type = "absolute", topN = 11)
itemFrequencyPlot(book_transactions, type = "absolute", topN = 12)
itemFrequencyPlot(book_transactions, type = "absolute", topN = 11)
# P2: Understand the book data
# Plot the frequency plot, using absolute count
# Which book category sells best?
# Write your code below:
itemFrequencyPlot(book,type="absolute", ylim = c(0, 1000), main = "Support count", col = "steelblue3", topN = 5)
Write your code below:
book_data_frame <- read.csv("book.csv")
book_matrix <- as.matrix(book_data_frame)
book <-  as(book_matrix,Class = "transactions")
inspect(head(book))
# P2: Understand the book data
# Plot the frequency plot, using absolute count
# Which book category sells best?
# Write your code below:
itemFrequencyPlot(book,type="absolute", ylim = c(0, 1000), main = "Support count", col = "steelblue3", topN = 5)
itemFrequencyPlot(book_transactions, type = "absolute", topN = 11)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ", topN = 5)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ",col= "blue", topN = 5)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ",col= "24477f", topN = 5)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ",col= "#24477f", topN = 5)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ",col= "#053259", topN = 5)
itemFrequencyPlot(book_transactions, ylim = c(0, 1000), type = "absolute",
main = "Top 5 genre ",col= "#053259", topN = 5)
# P3: Mine association rules
# Find all association rules with minsupp = 0.1 and minconf = 0.8
# Write your code below:
book_rules <- apriori(book_transactions, parameter = list(supp = 0.1, conf = 0.8))
# P3: Mine association rules
# Find all association rules with minsupp = 0.1 and minconf = 0.8
# Write your code below:
book_rules <- apriori(book_transactions, parameter = list(supp = 0.1, conf = 0.8))
# P4: Understand the rules found
# Inspect the rules, and answer the following questions:
# Which rule has the highest lift? What does it tell us?
# What can be done with this rule, if you were the bookstore manager?
# Write your code below:
inspect(book_rules)
# P4: Understand the rules found
# Inspect the rules, and answer the following questions:
# Which rule has the highest lift? What does it tell us?
# What can be done with this rule, if you were the bookstore manager?
# Write your code below:
inspect(sort(book_rules, by = "lift"))
#---------------------------------------------------------------------------------#
#P5: Plot the rules using arulezViz
#Load the package arulesViz, plot a graph of the rules
library(arulesViz)
#If you have a large dataset and a graph becomes infeasible
#we can plot a scatterplot of the rules, where the color changes based
#on a chosen measure
plot(rules, measure = c("support", "lift"), shading = "confidence")
#Finally, plot a scatterplot, where the shading changes depending on the confidence
plot(book_rules, measure = c("support", "lift"), shading = "confidence")
plot(book_rules)
plot(book_rules, method = "graph")
#Finally, plot a scatterplot, where the shading changes depending on the confidence
plot(book_rules, measure = c("support", "lift"), shading = "confidence")
